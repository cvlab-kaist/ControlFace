<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KPJS657TXE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KPJS657TXE');
</script>
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>ControlFace</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="img/Ret_cat.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="670">
    <meta property="og:image:height" content="670">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://cvlab-kaist.github.io/ControlFace/">
    <meta property="og:title" content="ControlFace: Harnessing Facial Parametric Control for Face Rigging">
    <meta property="og:description" content="">

    <!-- <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="ControlFace: Harnessing Facial Parametric Control for Face Rigging">
    <meta name="twitter:description" content="For text-to-3D generation, we propose to leverage the retrieved 3D asset to incorporate its geometric prior in the variational objective and adapt the diffusion model's 2D prior toward view consistency, resulting in facilitating generation of high-quality 3D assets with added controllability and negligible training cost."> -->
    <!-- <meta name="twitter:image" content="img/cats.png"> -->


    <!-- mirror: F0%9F%AA%9E&lt -->
    <!-- <link rel="icon" type="image/x-icon" href="img/retdream.ico"> -->
    <!-- <link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;"> -->
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="./css/twentytwenty.css">

    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/codemirror.min.js"></script>
    <script src="js/clipboard.min.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/app.js"></script>
    <script src="./js/jquery.twentytwenty.js"></script>
</head>
    <style>
        .spaced-row {
            margin-top: 520px; /* Adds spacing above the row */
        }
    </style>

<body>
    <div class="container" id="header" style="text-align: center; margin: auto;">
        <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
            <h2 class="col-md-12 text-center" id="title">
                ControlFace: Harnessing Facial Parametric Control for Face Rigging <br>
                <!-- <small>
                    ICML 2024
                </small> -->
            </h2>
        </div>
        <div class="row" id="author-row" style="margin:0 auto;">
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <a style="text-decoration:none">
                    Wooseok&nbsp;Jang<sup>,1</sup>
                </a>
                <span style="padding-left: 20px;"></span>
                <a style="text-decoration:none">
                    Youngjun&nbsp;Hong<sup>,2</sup>
                </a>
                <span style="padding-left: 20px;"></span>
                <a style="text-decoration:none">
                    Geonho&nbsp;Cha<sup>2</sup>
                </a>
                <span style="padding-left: 20px;"></span>
                <a style="text-decoration:none">
                    Seungryong&nbsp;Kim<sup>3</sup>
                </a>
                <table class="author-table" id="author-table" style="border-collapse: collapse; width: 10%; margin: auto;">
                    <tr>
                        <td style="padding: 5px; text-align: center;">
                            <sup>1</sup>Korea University
                        </td>
                        <td style="padding: 5px; text-align: center;text-indent: 20px;">
                            <sup>2</sup>NAVER Cloud
                        </td>
                        <td style="padding: 5px; text-align: center;">
                            <sup>3</sup>KAIST
                        </td>
                    </tr>
                </table>

                
            </div>
        </div>
    </div>
    <script>
        document.getElementById('author-row').style.maxWidth = document.getElementById("title-row").clientWidth + 'px';
    </script>
    <div class="container" id="main">
        <div class="row">
                <div class="col-sm-6 col-sm-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
<!--                             <a href="https://arxiv.org/abs/2402.02972"> -->
                            <img src="./img/paper_image.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/cvlab-kaist/ControlFace" target="_blank">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>
        
        <div class="text-center">
            <div class="col-md-8 col-md-offset-2">
        <img src="./img/caption.png" width="100%">
        <video id="ide" width="100%" playsinline autoplay loop muted>
            <source src="vid/5.mp4" type="video/mp4" />
        </video>
        <video id="ide" width="100%" playsinline autoplay loop muted>
            <source src="vid/10.mp4" type="video/mp4" />
        </video>
        <video id="ide" width="100%" playsinline autoplay loop muted>
            <source src="vid/13.mp4" type="video/mp4" />
        </video>
        <video id="ide" width="100%" playsinline autoplay loop muted>
            <source src="vid/14.mp4" type="video/mp4" />
        </video>
        <!-- <video id="ide" width="65%" playsinline autoplay loop muted>
            <source src="vid/30.mp4" type="video/mp4" />
        </video> -->
        
                <div class="text-justify">
                    Our <b>ControlFace</b> is capable of generating videos from sequential explicit facial parametric controls without compromising the identity and other semantic details such as hairstyle.
                </div>
            </div>
    </div>
        <div class="spaced-row">
            <div class="col-md-8 col-md-offset-2">
                <div class="text-center">
                    <img src="./img/teaser.png" width="100%">
                </div>

                <div class="text-justify">
                    Our <b>ControlFace</b> can edit the input face image using explicit facial parametric controls, generating realistic images without compromising the identity and other semantic details such as hairstyle.
                </div>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2"  style="margin-bottom: 5px;">
                <h3>
                    <b>Abstract</b>
                </h3>
                <div style="width: 100%;">
                    <div class="text-justify">
                        Manipulation of facial images to meet specific controls such as pose, expression, and lighting, also referred to as face rigging is a complex task in computer vision. Existing methods are limited by their reliance on image datasets, which necessitates individual-specific fine-tuning and limits their ability to retain fine-grained identity and semantic details, reducing practical usability. To overcome these limitations, we introduce ControlFace, a novel face rigging method conditioned on 3DMM renderings that enables flexible, high-fidelity control. We employ a dual-branch U-Nets: one, referred to as FaceNet, captures identity and fine details, while the other focuses on generation. To enhance control precision, control mixer module encodes the correlated features between the target-aligned control and reference-aligned control, and a novel guidance method, reference control guidance, steers the generation process for better control adherence. By training on a facial video dataset, we fully utilize FaceNet’s rich representations while ensuring control adherence. Extensive experiments demonstrate ControlFace’s superior performance in identity preservation, and control precision, highlighting its practicality. Code and pre-trained weights will be publicly available.
                    </div>
                </div>
                
                <br>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2"  style="margin-bottom: 5px;">
                <h3>
                    <b>Overall Architecture</b>
                </h3>
                <div class="text-justify">
                    ControlFace encodes the reference image into the FaceNet and CLIP image encoder for identity and semantic preservation. For generation control, the target control is incorporated into the denoising U-Net through face controller. To enhance the control adherence, the correlated feature between reference control and target control is acquired from the proposed control mixer module.
                </div>
                <br>

                <div class="text-center">
                    <img src="./img/main_fig.png" width="100%">
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2"  style="margin-bottom: 5px;">
                <h3>
                    <b>Qualitative Results</b>
                </h3>
                <h4>
                    <b>Results on FFHQ</b>
                </h4>
                <div class="text-center">
                    <img src="./img/ap_qual_0-1.png" width="100%">
                </div>
                <div class="text-center">
                </div>
                <h4>
                    <b>Results on Out-of-Domain</b>
                </h4>    
                <div class="text-center">
                    <img src="./img/ap_ood.png" width="100%">
                </div>
                
            </div>
        </div>


            <div class="row">
                <div class="col-md-8 col-md-offset-2">
                    <h3>
                        Acknowledgements
                    </h3>
                    <p class="text-justify">
                    <!-- We would like to thank Lior Yariv and Kai Zhang for helping us evaluate their methods, and Ricardo Martin-Brualla for helpful comments on our text. DV is supported by the National Science Foundation under Cooperative Agreement PHY-2019786 (an NSF AI Institute, <a href="http://iaifi.org">http://iaifi.org</a>) -->
                        <!-- <br> -->
                    The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a>.
                    </p>
                </div>
            </div>
        </div>


        </div>
        </div>


        


        


</body></html>
